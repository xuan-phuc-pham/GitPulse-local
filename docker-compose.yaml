version: '3'

services:
  db:
    container_name: postgres
    image: postgres:14.17
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=gh_archive
    volumes:
      - ./postgres/data:/var/lib/postgresql/data
      - ./postgres/airflow_init.sql:/docker-entrypoint-initdb.d/airflow_init.sql
    ports:
      - "5432:5432"
    networks:
      - nw-1
  pgadmin:
    image: dpage/pgadmin4
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@admin.com
      - PGADMIN_DEFAULT_PASSWORD=root
    ports:
      - "8082:80"
    networks:
      - nw-1
  af:
    build:
      context: .
      dockerfile: airflow.Dockerfile
    ports:
      - "8000:8080"
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@db:5432/airflow_db
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/config:/opt/airflow/config
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/data:/opt/airflow/data
      - ./spark_airflow:/opt/shared/spark_airflow
    depends_on:
      - db
    networks:
      - nw-1
    command: |
      bash -c "
        airflow db migrate;
        airflow standalone;
      "
    # command: >
    #   bash -c "airflow connections add spark_conn --conn-type spark --conn-host spark://spark-master:7077"

  spark-master:
    image: my_first_spark
    build:
      context: .
      dockerfile: spark.Dockerfile
    container_name: spark-master
    networks:
      - nw-1
    entrypoint: /bin/bash
    command: -c "/home/sparkuser/spark/sbin/start-master.sh; tail -f /dev/null"
    ports:
      - "8084:8080"
      - "4040:4040"
    volumes:
      - ./spark-events:/home/sparkuser/spark/events
      - ./spark_airflow:/opt/shared/spark_airflow
  spark-worker:
    image: my_first_spark
    build:
      context: .
      dockerfile: spark.Dockerfile
    container_name: spark-worker1
    networks:
      - nw-1
    entrypoint: /bin/bash
    command: -c "/home/sparkuser/spark/sbin/start-worker.sh  spark://spark-master:7077; tail -f /dev/null"
    volumes:
      - ./spark-events:/home/sparkuser/spark/events
      - ./spark_airflow:/opt/shared/spark_airflow
    
  spark-history-server:
    image: my_first_spark
    build:
      context: .
      dockerfile: spark.Dockerfile
    container_name: spark-history-server
    networks:
      - nw-1
    entrypoint: /bin/bash
    command: -c "/home/sparkuser/spark/sbin/start-history-server.sh; tail -f /dev/null"
    volumes:
      - ./spark-events:/home/sparkuser/spark/events
      - ./spark_airflow:/opt/shared/spark_airflow
    ports:
      - '18080:18080'
  
  dbt:
    container_name: dbt_container
    image: ghcr.io/dbt-labs/dbt-postgres:1.9.latest
    volumes:
      - ./dbt/usr/app:/usr/app
      - ./dbt:/root/.dbt
    working_dir: /usr/app/gh_pipeline
    environment:
      DBT_PROFILES_DIR: "/root/.dbt"
    depends_on:
      - db
    ports:
      - "8087:8080"
    networks:
      - nw-1

  minio:
    image:  minio/minio:RELEASE.2025-02-03T21-03-04Z-cpuv1
    container_name: minio
    ports:
      - "9000:9000" # API
      - "9001:9001" # WS
    environment:
      MINIO_ROOT_USER: xpham
      MINIO_ROOT_PASSWORD: xpham_minio
    command: server /data --console-address ":9001"
    volumes:
      - ./minio_data:/data
    networks:
      - nw-1

networks:
  nw-1:
    driver: bridge
    